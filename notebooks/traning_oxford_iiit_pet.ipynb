{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1963c672",
   "metadata": {},
   "source": [
    "##### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c10889c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
      "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (1.8.2)\n",
      "Requirement already satisfied: albumentations in /usr/local/lib/python3.12/dist-packages (2.0.8)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (0.15.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from albumentations) (1.16.3)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from albumentations) (6.0.3)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations) (2.11.10)\n",
      "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.12/dist-packages (from albumentations) (0.0.24)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.12/dist-packages (from albumentations) (4.12.0.88)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (4.2.3)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (6.5.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python torch torchvision torchmetrics albumentations matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1ef28251b463bd",
   "metadata": {},
   "source": [
    "##### Required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "id": "d67c6daaf4727e59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T12:22:35.573487Z",
     "start_time": "2025-12-03T12:22:30.869712Z"
    }
   },
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from typing import List, Tuple\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2  # np.array -> torch.tensor\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchmetrics.segmentation import GeneralizedDiceScore, MeanIoU"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "83493aa0b347a9b0",
   "metadata": {},
   "source": [
    "##### Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd240421",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-972715178.py:15: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall(\"/content/data\")\n",
      "/tmp/ipython-input-972715178.py:18: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall(\"/content/data\")\n"
     ]
    }
   ],
   "source": [
    "# Download and prepare the dataset\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "os.makedirs(\"/content/data\", exist_ok=True)\n",
    "\n",
    "# Download Oxford-IIIT Pet Dataset\n",
    "url = \"https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\"\n",
    "urllib.request.urlretrieve(url, \"/content/data/images.tar.gz\")\n",
    "\n",
    "url_annotations = \"https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\"\n",
    "urllib.request.urlretrieve(url_annotations, \"/content/data/annotations.tar.gz\")\n",
    "\n",
    "with tarfile.open(\"/content/data/images.tar.gz\", \"r:gz\") as tar:\n",
    "    tar.extractall(\"/content/data\")\n",
    "\n",
    "with tarfile.open(\"/content/data/annotations.tar.gz\", \"r:gz\") as tar:\n",
    "    tar.extractall(\"/content/data\")\n",
    "\n",
    "root = \"/content/data\"\n",
    "saved_directory = \"/content/saved\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41caaf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotations  annotations.tar.gz  images  images.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!ls /content/data"
   ]
  },
  {
   "cell_type": "code",
   "id": "65796e3362bc30db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T12:29:27.119790Z",
     "start_time": "2025-12-03T12:29:27.110522Z"
    }
   },
   "source": [
    "class OxfordIIIPetDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        is_train: bool = True,\n",
    "        transform=None,\n",
    "    ):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.classes = [\"background\", \"animal\"]\n",
    "        self.image_names: List[str] = []\n",
    "\n",
    "        if is_train:\n",
    "            annotations = os.path.join(root, \"annotations\", \"trainval.txt\")\n",
    "        else:\n",
    "            annotations = os.path.join(root, \"annotations\", \"test.txt\")\n",
    "\n",
    "        # Read the annotation file and extract image names\n",
    "        with open(annotations, \"r\") as f:\n",
    "            self.image_names = [image.split(' ')[0] for image in f.readlines()]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, item) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        image_name = self.image_names[item]\n",
    "        image_path = os.path.join(self.root, \"images\", image_name + \".jpg\")\n",
    "        mask_path = os.path.join(self.root, \"annotations\", \"trimaps\", image_name + \".png\")\n",
    "\n",
    "        # Read the image and convert it from BGR to RGB\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # type: ignore\n",
    "\n",
    "        # Read the mask and adjust its values\n",
    "        # 0.299 x Red + 0.587 x Green + 0.114 x Blue\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask[mask == 2] = 0  # type: ignore\n",
    "        mask[mask == 3] = 1  # type: ignore\n",
    "\n",
    "        # Apply transformations if provided\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=mask)\n",
    "            image = transformed[\"image\"]\n",
    "            mask = transformed[\"mask\"]\n",
    "\n",
    "        return image, mask  # type: ignore"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "dd482fde",
   "metadata": {},
   "source": [
    "##### Build U-Net model"
   ]
  },
  {
   "cell_type": "code",
   "id": "021feedf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T12:23:44.469559Z",
     "start_time": "2025-12-03T12:23:44.459659Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class DualConv(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        mid_channels: int | None = None,\n",
    "    ):\n",
    "        super(DualConv, self).__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        super(Down, self).__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DualConv(in_channels, out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, bilinear: bool = True):\n",
    "        super(Up, self).__init__()\n",
    "\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "            self.conv = DualConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                in_channels // 2,\n",
    "                kernel_size=2,\n",
    "                stride=2,\n",
    "            )\n",
    "            self.conv = DualConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \"\"\"\n",
    "        x1: from the previous layer - decoder\n",
    "        x2: from the skip connection - encoder\n",
    "        \"\"\"\n",
    "        x1 = self.up(x1)\n",
    "        diffY = x2.size()[2] - x1.size()[2]  # height\n",
    "        diffX = x2.size()[3] - x1.size()[3]  # width\n",
    "\n",
    "        # pad function: (L, R, T, B)\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
    "\n",
    "        # Concatenate along the channels axis\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNetBaseline(nn.Module):\n",
    "    def __init__(self, in_channels: int, num_classes: int):\n",
    "        super(UNetBaseline, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.inc = DualConv(in_channels, 32)\n",
    "        self.down1 = Down(32, 64)\n",
    "        self.down2 = Down(64, 128)\n",
    "        self.down3 = Down(128, 256)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.down4 = Down(256, 512)\n",
    "\n",
    "        # Decoder\n",
    "        self.up1 = Up(512, 256, bilinear=False)\n",
    "        self.up2 = Up(256, 128, bilinear=False)\n",
    "        self.up3 = Up(128, 64, bilinear=False)\n",
    "        self.up4 = Up(64, 32, bilinear=False)\n",
    "\n",
    "        # Output layer\n",
    "        self.outc = nn.Conv2d(32, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder with skip connections\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)  # Bottleneck\n",
    "\n",
    "        # Decoder with skip connections\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.outc(x)\n",
    "\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "5e646db27eb48d8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T12:30:50.451208Z",
     "start_time": "2025-12-03T12:30:50.439699Z"
    }
   },
   "source": [
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 10\n",
    "EPOCHS = 50\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "ROOT = \"/Users/hinsun/Workspace/ComputerScience/UNetWithBraTS\"\n",
    "ROOT_DATASET = ROOT + \"/data/OxfordIIITPet/oxford-iiit-pet\"\n",
    "MODEL_CHECK_POINT = ROOT + \"/checkpoints/oxford_iiit_pet\"\n",
    "if not os.path.exists(MODEL_CHECK_POINT):\n",
    "    os.makedirs(MODEL_CHECK_POINT)\n",
    "\n",
    "model_path = MODEL_CHECK_POINT\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(width=224, height=224),\n",
    "    A.HorizontalFlip(),\n",
    "    A.RandomBrightnessContrast(),\n",
    "    A.Blur(),\n",
    "    A.Sharpen(),\n",
    "    A.RGBShift(),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "train_dataset = OxfordIIIPetDataset(\n",
    "    root=ROOT_DATASET,\n",
    "    is_train=True,\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "val_dataset = OxfordIIIPetDataset(\n",
    "    root=ROOT_DATASET,\n",
    "    is_train=False,\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "8a7afc9196bc7c36",
   "metadata": {},
   "source": [
    "##### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "38ca1384",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T12:30:56.281404Z",
     "start_time": "2025-12-03T12:30:54.616732Z"
    }
   },
   "source": [
    "model = UNetBaseline(in_channels=3, num_classes=1)\n",
    "device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Metrics\n",
    "miou_metric = MeanIoU(num_classes=2)\n",
    "dice_metric = GeneralizedDiceScore(num_classes=2)\n",
    "\n",
    "# Best validation IoU for saving the best model\n",
    "best_predict = -1\n",
    "current_epoch = 0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    train_progress = tqdm(train_dataloader, colour=\"cyan\")\n",
    "\n",
    "    for idx, img_mask in enumerate(train_progress):\n",
    "        # B, C, H, W\n",
    "        img = img_mask[0].float().to(device)  # type: ignore\n",
    "        # B, H, W\n",
    "        mask = img_mask[1].float().to(device)\n",
    "\n",
    "        y_pred = model(img)  # B, 1, H, W\n",
    "        y_pred = y_pred.squeeze()  # B, H, W\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Calculate Loss\n",
    "        loss = criterion(y_pred, mask)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_progress.set_description(\"TRAIN| Epoch: {}/{}| Loss: {:0.4f}\".format(epoch, EPOCHS, loss))\n",
    "\n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "\n",
    "    all_losses = []\n",
    "    all_ious = []\n",
    "    all_dices = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, img_mask in enumerate(val_dataloader):\n",
    "            img = img_mask[0].float().to(device)  # type: ignore\n",
    "            mask = img_mask[1].float().to(device)  # B W H\n",
    "\n",
    "            y_pred = model(img)\n",
    "            y_pred = y_pred.squeeze()  # B H W\n",
    "\n",
    "            loss = criterion(y_pred, mask)\n",
    "\n",
    "            mask = mask.long().cpu()\n",
    "            y_pred[y_pred > 0] = 1  # BWH\n",
    "            y_pred[y_pred < 0] = 0  # BWH\n",
    "            y_pred = y_pred.long().cpu()\n",
    "\n",
    "            miou = miou_metric(y_pred, mask)\n",
    "            dice = dice_metric(y_pred, mask)\n",
    "\n",
    "            all_losses.append(loss.cpu().item())\n",
    "            all_ious.append(miou.cpu().item())\n",
    "            all_dices.append(dice.cpu().item())\n",
    "\n",
    "            if idx == 40: break\n",
    "\n",
    "    # Compute mean IoU for the epoch\n",
    "    loss = np.mean(all_losses)\n",
    "    miou = np.mean(all_ious)\n",
    "    dice = np.mean(all_dices)\n",
    "\n",
    "    print(\"VAL| Loss: {:0.4f} | mIOU: {:0.4f} | Dice: {:0.4f}\".format(loss, miou, dice))\n",
    "\n",
    "    checkpoint = {\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"epoch\": epoch,\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"miou\": miou\n",
    "    }\n",
    "\n",
    "    # Save Last Checkpoint\n",
    "    torch.save(checkpoint, os.path.join(model_path, \"last.h5\"))\n",
    "\n",
    "    # Save best checkpoint based on IoU\n",
    "    if miou > best_predict:\n",
    "        torch.save(checkpoint, os.path.join(model_path, \"best.pth\"))\n",
    "        best_predict = miou"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001B[36m          \u001B[0m| 0/368 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \u001B[35m\"<string>\"\u001B[0m, line \u001B[35m1\u001B[0m, in \u001B[35m<module>\u001B[0m\n",
      "    from multiprocessing.spawn import spawn_main; \u001B[31mspawn_main\u001B[0m\u001B[1;31m(tracker_fd=95, pipe_handle=119)\u001B[0m\n",
      "                                                  \u001B[31m~~~~~~~~~~\u001B[0m\u001B[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001B[0m\n",
      "  File \u001B[35m\"/Users/hinsun/Workspace/ComputerScience/UNetWithBraTS/.venv/lib/python3.13/multiprocessing/spawn.py\"\u001B[0m, line \u001B[35m122\u001B[0m, in \u001B[35mspawn_main\u001B[0m\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \u001B[35m\"/Users/hinsun/Workspace/ComputerScience/UNetWithBraTS/.venv/lib/python3.13/multiprocessing/spawn.py\"\u001B[0m, line \u001B[35m132\u001B[0m, in \u001B[35m_main\u001B[0m\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "\u001B[1;35mAttributeError\u001B[0m: \u001B[35mCan't get attribute 'OxfordIIIPetDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\u001B[0m\n",
      "  File \u001B[35m\"<string>\"\u001B[0m, line \u001B[35m1\u001B[0m, in \u001B[35m<module>\u001B[0m\n",
      "    from multiprocessing.spawn import spawn_main; \u001B[31mspawn_main\u001B[0m\u001B[1;31m(tracker_fd=95, pipe_handle=112)\u001B[0m\n",
      "                                                  \u001B[31m~~~~~~~~~~\u001B[0m\u001B[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001B[0m\n",
      "  File \u001B[35m\"/Users/hinsun/Workspace/ComputerScience/UNetWithBraTS/.venv/lib/python3.13/multiprocessing/spawn.py\"\u001B[0m, line \u001B[35m122\u001B[0m, in \u001B[35mspawn_main\u001B[0m\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \u001B[35m\"/Users/hinsun/Workspace/ComputerScience/UNetWithBraTS/.venv/lib/python3.13/multiprocessing/spawn.py\"\u001B[0m, line \u001B[35m132\u001B[0m, in \u001B[35m_main\u001B[0m\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "\u001B[1;35mAttributeError\u001B[0m: \u001B[35mCan't get attribute 'OxfordIIIPetDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\u001B[0m\n",
      "  File \u001B[35m\"<string>\"\u001B[0m, line \u001B[35m1\u001B[0m, in \u001B[35m<module>\u001B[0m\n",
      "    from multiprocessing.spawn import spawn_main; \u001B[31mspawn_main\u001B[0m\u001B[1;31m(tracker_fd=95, pipe_handle=126)\u001B[0m\n",
      "                                                  \u001B[31m~~~~~~~~~~\u001B[0m\u001B[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001B[0m\n",
      "  File \u001B[35m\"/Users/hinsun/Workspace/ComputerScience/UNetWithBraTS/.venv/lib/python3.13/multiprocessing/spawn.py\"\u001B[0m, line \u001B[35m122\u001B[0m, in \u001B[35mspawn_main\u001B[0m\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \u001B[35m\"/Users/hinsun/Workspace/ComputerScience/UNetWithBraTS/.venv/lib/python3.13/multiprocessing/spawn.py\"\u001B[0m, line \u001B[35m132\u001B[0m, in \u001B[35m_main\u001B[0m\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "\u001B[1;35mAttributeError\u001B[0m: \u001B[35mCan't get attribute 'OxfordIIIPetDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\u001B[0m\n",
      "Traceback (most recent call last):\n",
      "  File \u001B[35m\"<string>\"\u001B[0m, line \u001B[35m1\u001B[0m, in \u001B[35m<module>\u001B[0m\n",
      "    from multiprocessing.spawn import spawn_main; \u001B[31mspawn_main\u001B[0m\u001B[1;31m(tracker_fd=95, pipe_handle=133)\u001B[0m\n",
      "                                                  \u001B[31m~~~~~~~~~~\u001B[0m\u001B[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001B[0m\n",
      "  File \u001B[35m\"/Users/hinsun/Workspace/ComputerScience/UNetWithBraTS/.venv/lib/python3.13/multiprocessing/spawn.py\"\u001B[0m, line \u001B[35m122\u001B[0m, in \u001B[35mspawn_main\u001B[0m\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \u001B[35m\"/Users/hinsun/Workspace/ComputerScience/UNetWithBraTS/.venv/lib/python3.13/multiprocessing/spawn.py\"\u001B[0m, line \u001B[35m132\u001B[0m, in \u001B[35m_main\u001B[0m\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "\u001B[1;35mAttributeError\u001B[0m: \u001B[35mCan't get attribute 'OxfordIIIPetDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\u001B[0m\n",
      "  0%|\u001B[36m          \u001B[0m| 0/368 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 12704, 12705) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/ComputerScience/UNetWithBraTS/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:1275\u001B[39m, in \u001B[36m_MultiProcessingDataLoaderIter._try_get_data\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m   1274\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1275\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_data_queue\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1276\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/ComputerScience/UNetWithBraTS/.venv/lib/python3.13/multiprocessing/queues.py:111\u001B[39m, in \u001B[36mQueue.get\u001B[39m\u001B[34m(self, block, timeout)\u001B[39m\n\u001B[32m    110\u001B[39m timeout = deadline - time.monotonic()\n\u001B[32m--> \u001B[39m\u001B[32m111\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[32m    112\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m Empty\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/ComputerScience/UNetWithBraTS/.venv/lib/python3.13/multiprocessing/connection.py:257\u001B[39m, in \u001B[36m_ConnectionBase.poll\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    256\u001B[39m \u001B[38;5;28mself\u001B[39m._check_readable()\n\u001B[32m--> \u001B[39m\u001B[32m257\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/ComputerScience/UNetWithBraTS/.venv/lib/python3.13/multiprocessing/connection.py:440\u001B[39m, in \u001B[36mConnection._poll\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    439\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_poll\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout):\n\u001B[32m--> \u001B[39m\u001B[32m440\u001B[39m     r = \u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    441\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mbool\u001B[39m(r)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/ComputerScience/UNetWithBraTS/.venv/lib/python3.13/multiprocessing/connection.py:1148\u001B[39m, in \u001B[36mwait\u001B[39m\u001B[34m(object_list, timeout)\u001B[39m\n\u001B[32m   1147\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1148\u001B[39m     ready = \u001B[43mselector\u001B[49m\u001B[43m.\u001B[49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1149\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m ready:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/ComputerScience/UNetWithBraTS/.venv/lib/python3.13/selectors.py:398\u001B[39m, in \u001B[36m_PollLikeSelector.select\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    397\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m398\u001B[39m     fd_event_list = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_selector\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpoll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    399\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/ComputerScience/UNetWithBraTS/.venv/lib/python3.13/site-packages/torch/utils/data/_utils/signal_handling.py:73\u001B[39m, in \u001B[36m_set_SIGCHLD_handler.<locals>.handler\u001B[39m\u001B[34m(signum, frame)\u001B[39m\n\u001B[32m     70\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mhandler\u001B[39m(signum, frame):\n\u001B[32m     71\u001B[39m     \u001B[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001B[39;00m\n\u001B[32m     72\u001B[39m     \u001B[38;5;66;03m# Python can still get and update the process status successfully.\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m73\u001B[39m     \u001B[43m_error_if_any_worker_fails\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     74\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m previous_handler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[31mRuntimeError\u001B[39m: DataLoader worker (pid 12705) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 22\u001B[39m\n\u001B[32m     19\u001B[39m model.train()\n\u001B[32m     20\u001B[39m train_progress = tqdm(train_dataloader, colour=\u001B[33m\"\u001B[39m\u001B[33mcyan\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m22\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimg_mask\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrain_progress\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     23\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# B, C, H, W\u001B[39;49;00m\n\u001B[32m     24\u001B[39m \u001B[43m    \u001B[49m\u001B[43mimg\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mimg_mask\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfloat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore\u001B[39;49;00m\n\u001B[32m     25\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# B, H, W\u001B[39;49;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/ComputerScience/UNetWithBraTS/.venv/lib/python3.13/site-packages/tqdm/std.py:1181\u001B[39m, in \u001B[36mtqdm.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1178\u001B[39m time = \u001B[38;5;28mself\u001B[39m._time\n\u001B[32m   1180\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1181\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   1182\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\n\u001B[32m   1183\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Update and possibly print the progressbar.\u001B[39;49;00m\n\u001B[32m   1184\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;49;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/ComputerScience/UNetWithBraTS/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:732\u001B[39m, in \u001B[36m_BaseDataLoaderIter.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    729\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    730\u001B[39m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[32m    731\u001B[39m     \u001B[38;5;28mself\u001B[39m._reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m732\u001B[39m data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    733\u001B[39m \u001B[38;5;28mself\u001B[39m._num_yielded += \u001B[32m1\u001B[39m\n\u001B[32m    734\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    735\u001B[39m     \u001B[38;5;28mself\u001B[39m._dataset_kind == _DatasetKind.Iterable\n\u001B[32m    736\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    737\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._num_yielded > \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called\n\u001B[32m    738\u001B[39m ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/ComputerScience/UNetWithBraTS/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:1482\u001B[39m, in \u001B[36m_MultiProcessingDataLoaderIter._next_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1479\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._process_data(data, worker_id)\n\u001B[32m   1481\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m._shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._tasks_outstanding > \u001B[32m0\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1482\u001B[39m idx, data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1483\u001B[39m \u001B[38;5;28mself\u001B[39m._tasks_outstanding -= \u001B[32m1\u001B[39m\n\u001B[32m   1484\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._dataset_kind == _DatasetKind.Iterable:\n\u001B[32m   1485\u001B[39m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/ComputerScience/UNetWithBraTS/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:1444\u001B[39m, in \u001B[36m_MultiProcessingDataLoaderIter._get_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1440\u001B[39m     \u001B[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001B[39;00m\n\u001B[32m   1441\u001B[39m     \u001B[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001B[39;00m\n\u001B[32m   1442\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1443\u001B[39m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1444\u001B[39m         success, data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_try_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1445\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[32m   1446\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/ComputerScience/UNetWithBraTS/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:1288\u001B[39m, in \u001B[36m_MultiProcessingDataLoaderIter._try_get_data\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m   1286\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(failed_workers) > \u001B[32m0\u001B[39m:\n\u001B[32m   1287\u001B[39m     pids_str = \u001B[33m\"\u001B[39m\u001B[33m, \u001B[39m\u001B[33m\"\u001B[39m.join(\u001B[38;5;28mstr\u001B[39m(w.pid) \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m failed_workers)\n\u001B[32m-> \u001B[39m\u001B[32m1288\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m   1289\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mDataLoader worker (pid(s) \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpids_str\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m) exited unexpectedly\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1290\u001B[39m     ) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01me\u001B[39;00m\n\u001B[32m   1291\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e, queue.Empty):\n\u001B[32m   1292\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[31mRuntimeError\u001B[39m: DataLoader worker (pid(s) 12704, 12705) exited unexpectedly"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
