{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T13:49:34.825610Z",
     "start_time": "2025-12-05T13:49:34.821260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from metrics import SegmentationMetrics, MultiClassSegmentationMetrics\n",
    "from models import UNetBaseline, ResUNet, AttentionUNet, TransUNet\n",
    "from losses import CombinedLoss, MultiClassDiceLoss, MultiClassCombinedLoss, DiceLoss"
   ],
   "id": "ac9e28ac28bcdfac",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### For Binary Segmentation",
   "id": "491ef18ad7f17f3"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-05T13:53:31.464943Z",
     "start_time": "2025-12-05T13:53:29.808733Z"
    }
   },
   "source": [
    "NUM_CLASSES = 2\n",
    "EPSILON = 1e-7\n",
    "THRESHOLD = 0.5\n",
    "BATCH_SIZE = 8\n",
    "HEIGHT, WIDTH = 128, 128\n",
    "CHANNELS = 3\n",
    "DEVICE = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Metrics\n",
    "metrics = SegmentationMetrics(threshold=THRESHOLD, epsilon=EPSILON)\n",
    "\n",
    "# Loss function\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = CombinedLoss(bce_weight=0.5, dice_weight=0.5)\n",
    "\n",
    "# num_classes = 1 for binary segmentation with BCEWithLogitsLoss\n",
    "# model = ResUNet(in_channels=CHANNELS, num_classes=1).to(DEVICE)\n",
    "# model = AttentionUNet(in_channels=CHANNELS, num_classes=1).to(DEVICE)\n",
    "model = TransUNet(in_channels=CHANNELS, num_classes=1).to(DEVICE)\n",
    "\n",
    "# 1. Init images and sample masks\n",
    "\n",
    "# Shape: [batch_size, channels, height, width] : [8, 3, 128, 128]\n",
    "images = torch.randn(BATCH_SIZE, CHANNELS, HEIGHT, WIDTH).to(DEVICE)\n",
    "# Shape: [batch_size, height, width] : [8, 128, 128]\n",
    "masks = torch.randint(0, 2, (BATCH_SIZE, HEIGHT, WIDTH)).long().to(DEVICE)  # {0, 1}\n",
    "\n",
    "assert images.shape == (BATCH_SIZE, CHANNELS, HEIGHT, WIDTH)\n",
    "assert masks.shape == (BATCH_SIZE, HEIGHT, WIDTH)\n",
    "\n",
    "# 2. Forward pass\n",
    "\n",
    "# Shape: [batch_size, 1, height, width] : [8, 1, 128, 128]\n",
    "pred = model(images)\n",
    "assert pred.shape == (BATCH_SIZE, 1, HEIGHT, WIDTH)\n",
    "\n",
    "# 3. Compute loss\n",
    "# For binary segmentation, use BCEWithLogitsLoss\n",
    "pred = pred.squeeze(1)  # Shape: [batch_size, height, width]\n",
    "loss = criterion(pred, masks.float())  # Should be a float value\n",
    "\n",
    "# BCEWithLogitsLoss: 0.7238839864730835\n",
    "# CombinedLoss: 0.5920742750167847\n",
    "\n",
    "# 4. Compute metrics\n",
    "pred_probs = F.sigmoid(pred)  # Convert logits to probabilities\n",
    "iou = metrics.compute_iou(pred_probs, masks)\n",
    "dice = metrics.compute_dice_score(pred_probs, masks)\n",
    "\n",
    "print(\"Loss:\", loss.item())\n",
    "print(\"IoU:\", iou)\n",
    "print(\"Dice:\", dice)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5896185040473938\n",
      "IoU: 0.4748704135417938\n",
      "Dice: 0.6439486742019653\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### For Multi-class Segmentation",
   "id": "28aa4d74c5f3cfcc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T12:15:53.351326Z",
     "start_time": "2025-12-05T12:15:53.140662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "NUM_CLASSES = 3\n",
    "EPSILON = 1e-7\n",
    "THRESHOLD = 0.5\n",
    "BATCH_SIZE = 8\n",
    "HEIGHT, WIDTH = 128, 128\n",
    "CHANNELS = 3\n",
    "DEVICE = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Metrics\n",
    "metrics = MultiClassSegmentationMetrics(num_classes=NUM_CLASSES, epsilon=EPSILON)\n",
    "\n",
    "# Loss function\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# criterion = MultiClassDiceLoss(num_classes=NUM_CLASSES, epsilon=EPSILON)\n",
    "criterion = MultiClassCombinedLoss(num_classes=NUM_CLASSES)\n",
    "\n",
    "# num_classes = 3 for multi-class segmentation\n",
    "# model = UNetBaseline(in_channels=CHANNELS, num_classes=NUM_CLASSES).to(DEVICE)\n",
    "model = ResUNet(in_channels=CHANNELS, num_classes=NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "# 1. Init images and sample masks\n",
    "# Shape: [batch_size, channels, height, width] : [8, 3, 128, 128]\n",
    "images = torch.randn(BATCH_SIZE, CHANNELS, HEIGHT, WIDTH).to(DEVICE)\n",
    "# Shape: [batch_size, height, width] : [8, 128, 128]\n",
    "masks = torch.randint(0, NUM_CLASSES, (BATCH_SIZE, HEIGHT, WIDTH)).long().to(DEVICE)\n",
    "\n",
    "assert images.shape == (BATCH_SIZE, CHANNELS, HEIGHT, WIDTH)\n",
    "assert masks.shape == (BATCH_SIZE, HEIGHT, WIDTH)\n",
    "\n",
    "# 2. Forward pass\n",
    "# Shape: [batch_size, num_classes, height, width] : [8, 3, 128, 128]\n",
    "pred = model(images)\n",
    "assert pred.shape == (BATCH_SIZE, NUM_CLASSES, HEIGHT, WIDTH)\n",
    "\n",
    "# 3. Compute loss\n",
    "loss = criterion(pred, masks)  # Should be a float value\n",
    "\n",
    "# CrossEntropyLoss: 1.1529099941253662\n",
    "# MultiClassDiceLoss: 0.6677639484405518\n",
    "# MultiClassCombinedLoss: 0.910336971282959\n",
    "\n",
    "loss.item()\n",
    "\n",
    "# 4. Compute metrics\n",
    "iou = metrics.compute_iou(pred, masks)\n",
    "dice = metrics.compute_dice_score(pred, masks)\n",
    "\n",
    "print(f\"Loss: {loss.item()}\")\n",
    "print(f\"IoU: {iou}\")\n",
    "print(f\"Dice Score: {dice}\")"
   ],
   "id": "3367ea4a7ed7850b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bridge shape: torch.Size([8, 512, 8, 8])\n",
      "Loss: 0.9455935955047607\n",
      "IoU: 0.1975846290588379\n",
      "Dice Score: 0.3287372887134552\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T13:52:51.250889Z",
     "start_time": "2025-12-05T13:52:49.588234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "NUM_CLASSES = 3\n",
    "EPSILON = 1e-7\n",
    "THRESHOLD = 0.5\n",
    "BATCH_SIZE = 8\n",
    "HEIGHT, WIDTH = 128, 128\n",
    "CHANNELS = 3\n",
    "DEVICE = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Configuration for TransUNet\n",
    "PATCH_SIZE = 16\n",
    "EMBEDDING_DIM = 768\n",
    "DEPTH = 12\n",
    "NUM_HEADS = 12\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "model = TransUNet(\n",
    "    img_size=HEIGHT,\n",
    "    in_channels=CHANNELS,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    patch_size=PATCH_SIZE,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    depth=DEPTH,\n",
    "    num_heads=NUM_HEADS,\n",
    ").to(DEVICE)\n",
    "\n",
    "# Metrics\n",
    "metrics = MultiClassSegmentationMetrics(num_classes=NUM_CLASSES, epsilon=EPSILON)\n",
    "\n",
    "# Loss function\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# criterion = MultiClassDiceLoss(num_classes=NUM_CLASSES, epsilon=EPSILON)\n",
    "criterion = MultiClassCombinedLoss(num_classes=NUM_CLASSES)\n",
    "\n",
    "# 1. Init images and sample masks\n",
    "# Shape: [batch_size, channels, height, width] : [8, 3, 128, 128]\n",
    "images = torch.randn(BATCH_SIZE, CHANNELS, HEIGHT, WIDTH).to(DEVICE)\n",
    "# Shape: [batch_size, height, width] : [8, 128, 128]\n",
    "masks = torch.randint(0, NUM_CLASSES, (BATCH_SIZE, HEIGHT, WIDTH)).long().to(DEVICE)\n",
    "\n",
    "assert images.shape == (BATCH_SIZE, CHANNELS, HEIGHT, WIDTH)\n",
    "assert masks.shape == (BATCH_SIZE, HEIGHT, WIDTH)\n",
    "\n",
    "# 2. Forward pass\n",
    "# Shape: [batch_size, num_classes, height, width] : [8, 3, 128, 128]\n",
    "pred = model(images)\n",
    "assert pred.shape == (BATCH_SIZE, NUM_CLASSES, HEIGHT, WIDTH)\n",
    "\n",
    "# 3. Compute loss\n",
    "loss = criterion(pred, masks)  # Should be a float value\n",
    "\n",
    "# CrossEntropyLoss: 1.1529099941253662\n",
    "# MultiClassDiceLoss: 0.6677639484405518\n",
    "# MultiClassCombinedLoss: 0.910336971282959\n",
    "\n",
    "loss.item()\n",
    "\n",
    "# 4. Compute metrics\n",
    "iou = metrics.compute_iou(pred, masks)\n",
    "dice = metrics.compute_dice_score(pred, masks)\n",
    "\n",
    "print(f\"Loss: {loss.item()}\")\n",
    "print(f\"IoU: {iou}\")\n",
    "print(f\"Dice Score: {dice}\")"
   ],
   "id": "5d49e5dfa9c647d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9132993817329407\n",
      "IoU: 0.1756775826215744\n",
      "Dice Score: 0.2911100387573242\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
