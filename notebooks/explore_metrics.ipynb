{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:09:55.714760Z",
     "start_time": "2025-12-04T09:09:55.712549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm"
   ],
   "id": "ac9e28ac28bcdfac",
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:10:55.022385Z",
     "start_time": "2025-12-04T09:10:55.015627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DualConv(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        mid_channels: int | None = None,\n",
    "    ):\n",
    "        super(DualConv, self).__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        super(Down, self).__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DualConv(in_channels, out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, bilinear: bool = True):\n",
    "        super(Up, self).__init__()\n",
    "\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "            self.conv = DualConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                in_channels // 2,\n",
    "                kernel_size=2,\n",
    "                stride=2,\n",
    "            )\n",
    "            self.conv = DualConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \"\"\"\n",
    "        x1: from the previous layer - decoder\n",
    "        x2: from the skip connection - encoder\n",
    "        \"\"\"\n",
    "        x1 = self.up(x1)\n",
    "        diffY = x2.size()[2] - x1.size()[2]  # height\n",
    "        diffX = x2.size()[3] - x1.size()[3]  # width\n",
    "\n",
    "        # pad function: (L, R, T, B)\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
    "\n",
    "        # Concatenate along the channels axis\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNetBaseline(nn.Module):\n",
    "    def __init__(self, in_channels: int, num_classes: int):\n",
    "        super(UNetBaseline, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        # self.inc = DualConv(in_channels, 64)\n",
    "        # self.down1 = Down(64, 128)\n",
    "        # self.down2 = Down(128, 256)\n",
    "        # self.down3 = Down(256, 512)\n",
    "\n",
    "        # # Bottleneck\n",
    "        # self.down4 = Down(512, 1024)\n",
    "\n",
    "        # # Decoder\n",
    "        # self.up1 = Up(1024, 512, bilinear=False)\n",
    "        # self.up2 = Up(512, 256, bilinear=False)\n",
    "        # self.up3 = Up(256, 128, bilinear=False)\n",
    "        # self.up4 = Up(128, 64, bilinear=False)\n",
    "\n",
    "        # Output layer\n",
    "        # self.outc = nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "\n",
    "        # Smaller UNet for faster training\n",
    "        self.inc = DualConv(in_channels, 32)\n",
    "        self.down1 = Down(32, 64)\n",
    "        self.down2 = Down(64, 128)\n",
    "        self.down3 = Down(128, 256)\n",
    "        self.down4 = Down(256, 512)  # Bottleneck\n",
    "        self.up1 = Up(512, 256, bilinear=False)\n",
    "        self.up2 = Up(256, 128, bilinear=False)\n",
    "        self.up3 = Up(128, 64, bilinear=False)\n",
    "        self.up4 = Up(64, 32, bilinear=False)\n",
    "        self.outc = nn.Conv2d(32, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder with skip connections\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)  # Bottleneck\n",
    "\n",
    "        # Decoder with skip connections\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.outc(x)\n",
    "\n",
    "        return x"
   ],
   "id": "4f4113fbd7ada586",
   "outputs": [],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:11:37.584416Z",
     "start_time": "2025-12-04T09:11:37.577340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SegmentationMetrics:\n",
    "    def __init__(self, threshold=0.5, epsilon: float = 1e-7):\n",
    "        self.threshold = threshold\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def compute_dice_score(self, pred, target) -> float:\n",
    "        \"\"\"\n",
    "        Compute Dice Score.\n",
    "        Formula:\n",
    "            Dice Score = (2 * |A ∩ B|) / (|A| + |B|)\n",
    "\n",
    "        Args:\n",
    "            pred: Predicted mask (B, H, W) - logits (after sigmoid)\n",
    "            target: Ground truth mask (B, H, W) - ground truth binary values {0, 1}\n",
    "\n",
    "        Returns:\n",
    "            Dice score value\n",
    "        \"\"\"\n",
    "        pred = (pred > self.threshold).float()  # Binarize predictions\n",
    "\n",
    "        # Flatten tensors\n",
    "        pred = pred.view(-1)\n",
    "        target = target.view(-1)\n",
    "\n",
    "        intersection = (pred * target).sum()\n",
    "        dice = (2. * intersection + self.epsilon) / (pred.sum() + target.sum() + self.epsilon)\n",
    "\n",
    "        return dice.item()\n",
    "\n",
    "    def compute_iou(self, pred, target) -> float:\n",
    "        \"\"\"\n",
    "        Compute Intersection over Union (IoU).\n",
    "        Formula:\n",
    "            IoU = |A ∩ B| / |A ∪ B|\n",
    "\n",
    "        Args:\n",
    "            pred: Predicted mask (B, H, W) - logits (after sigmoid)\n",
    "            target: Ground truth mask (B, H, W) - ground truth binary values {0, 1}\n",
    "        Returns:\n",
    "            IoU score value\n",
    "        \"\"\"\n",
    "        pred_binary = (pred > self.threshold).float()\n",
    "        pred = pred_binary.view(-1)\n",
    "        target = target.view(-1)\n",
    "\n",
    "        intersection = (pred * target).sum()\n",
    "        union = pred.sum() + target.sum() - intersection\n",
    "        iou = (intersection + self.epsilon) / (union + self.epsilon)\n",
    "        return iou.item()\n",
    "\n",
    "    def compute_pixel_accuracy(self, pred, target) -> float:\n",
    "        pred_binary = (pred > self.threshold).float()\n",
    "        correct = (pred_binary == target).float().sum()  # type: ignore\n",
    "        total = target.numel()\n",
    "        return (correct / total).item()"
   ],
   "id": "47fbb8c24431740a",
   "outputs": [],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:13:36.125880Z",
     "start_time": "2025-12-04T09:13:36.116797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, epsilon: float = 1e-7):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, pred, target) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculate Dice Loss.\n",
    "        Formula:\n",
    "            Dice Score = (2 * |A ∩ B|) / (|A| + |B|)\n",
    "            Dice Loss = 1 - Dice Score\n",
    "\n",
    "        Args:\n",
    "            pred: Predicted mask (B, H, W) - logits (before sigmoid)\n",
    "            target: Ground truth mask (B, H, W) - ground truth binary values {0, 1}\n",
    "        Returns:\n",
    "            Dice loss value\n",
    "        \"\"\"\n",
    "        pred = torch.sigmoid(pred)  # Apply sigmoid to get probabilities\n",
    "        pred = pred.view(-1)\n",
    "        target = target.view(-1)\n",
    "\n",
    "        intersection = (pred * target).sum()\n",
    "        dice = (2. * intersection + self.epsilon) / (pred.sum() + target.sum() + self.epsilon)\n",
    "\n",
    "        return 1 - dice\n",
    "\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, bce_weight=0.5, dice_weight=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.bce_weight = bce_weight\n",
    "        self.dice_weight = dice_weight\n",
    "\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss()\n",
    "        self.dice_loss = DiceLoss()\n",
    "\n",
    "    def forward(self, pred, target) -> torch.Tensor:\n",
    "        bce = self.bce_loss(pred, target.float())\n",
    "        dice = self.dice_loss(pred, target.float())\n",
    "\n",
    "        combined_loss = self.bce_weight * bce + self.dice_weight * dice\n",
    "        return combined_loss"
   ],
   "id": "2b8e01cc34683179",
   "outputs": [],
   "execution_count": 130
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### For Binary Segmentation",
   "id": "491ef18ad7f17f3"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-04T09:17:02.297139Z",
     "start_time": "2025-12-04T09:17:01.676367Z"
    }
   },
   "source": [
    "NUM_CLASSES = 2\n",
    "EPSILON = 1e-7\n",
    "THRESHOLD = 0.5\n",
    "BATCH_SIZE = 8\n",
    "HEIGHT, WIDTH = 128, 128\n",
    "CHANNELS = 3\n",
    "DEVICE = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Metrics\n",
    "metrics = SegmentationMetrics(threshold=THRESHOLD, epsilon=EPSILON)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# criterion = CombinedLoss(bce_weight=0.5, dice_weight=0.5)\n",
    "\n",
    "# num_classes = 1 for binary segmentation with BCEWithLogitsLoss\n",
    "model = UNetBaseline(in_channels=CHANNELS, num_classes=1).to(DEVICE)\n",
    "\n",
    "# 1. Init images and sample masks\n",
    "\n",
    "# Shape: [batch_size, channels, height, width] : [8, 3, 128, 128]\n",
    "images = torch.randn(BATCH_SIZE, CHANNELS, HEIGHT, WIDTH).to(DEVICE)\n",
    "# Shape: [batch_size, height, width] : [8, 128, 128]\n",
    "masks = torch.randint(0, 2, (BATCH_SIZE, HEIGHT, WIDTH)).long().to(DEVICE)  # {0, 1}\n",
    "\n",
    "assert images.shape == (BATCH_SIZE, CHANNELS, HEIGHT, WIDTH)\n",
    "assert masks.shape == (BATCH_SIZE, HEIGHT, WIDTH)\n",
    "\n",
    "# 2. Forward pass\n",
    "\n",
    "# Shape: [batch_size, 1, height, width] : [8, 1, 128, 128]\n",
    "pred = model(images)\n",
    "assert pred.shape == (BATCH_SIZE, 1, HEIGHT, WIDTH)\n",
    "\n",
    "# 3. Compute loss\n",
    "# For binary segmentation, use BCEWithLogitsLoss\n",
    "pred = pred.squeeze(1)  # Shape: [batch_size, height, width]\n",
    "loss = criterion(pred, masks.float())  # Should be a float value\n",
    "\n",
    "# BCEWithLogitsLoss: 0.7238839864730835\n",
    "# CombinedLoss: 0.5920742750167847\n",
    "\n",
    "# 4. Compute metrics\n",
    "pred_probs = F.sigmoid(pred)  # Convert logits to probabilities\n",
    "iou = metrics.compute_iou(pred_probs, masks)\n",
    "dice = metrics.compute_dice_score(pred_probs, masks)\n",
    "pixel_acc = metrics.compute_pixel_accuracy(pred_probs, masks)\n",
    "\n",
    "print(f\"Loss: {loss.item()}\")\n",
    "print(f\"IoU: {iou}\")\n",
    "print(f\"Dice Score: {dice}\")\n",
    "print(f\"Pixel Accuracy: {pixel_acc}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7238839864730835\n",
      "IoU: 0.4617643356323242\n",
      "Dice Score: 0.6317903995513916\n",
      "Pixel Accuracy: 0.49936676025390625\n"
     ]
    }
   ],
   "execution_count": 136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:27:58.592083Z",
     "start_time": "2025-12-04T09:27:58.579818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MultiClassDiceLoss(nn.Module):\n",
    "    def __init__(self, num_classes: int, epsilon: float = 1e-7):\n",
    "        super(MultiClassDiceLoss, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        \"\"\"\n",
    "        Compute Dice Loss for multi-class segmentation.\n",
    "        Formula:\n",
    "            Dice Score = (2 * |A ∩ B|) / (|A| + |B|)\n",
    "            Dice Loss = 1 - Dice Score\n",
    "        Args:\n",
    "            pred: Predicted mask (B, C, H, W) - logits (before softmax)\n",
    "            target: Ground truth mask (B, H, W) - ground truth class indices {0, 1, ..., C-1}\n",
    "        \"\"\"\n",
    "        # Convert logits to probabilities\n",
    "        pred = F.softmax(pred, dim=1)  # [B, C, H, W]\n",
    "\n",
    "        # Convert target to one-hot encoding\n",
    "        target_oh = F.one_hot(target, self.num_classes)  # [B, H, W, C]\n",
    "        target_oh = target_oh.permute(0, 3, 1, 2).float()  # [B, C, H, W]\n",
    "\n",
    "        # Compute Dice for each class\n",
    "        dice_scores = []\n",
    "        for cls in range(self.num_classes):\n",
    "            pred_cls = pred[:, cls, :, :].contiguous().view(-1)\n",
    "            target_cls = target_oh[:, cls, :, :].contiguous().view(-1)\n",
    "\n",
    "            intersection = (pred_cls * target_cls).sum()\n",
    "            dice = (2. * intersection + self.epsilon) / (pred_cls.sum() + target_cls.sum() + self.epsilon)\n",
    "            dice_scores.append(dice)\n",
    "\n",
    "        # Average Dice loss over all classes\n",
    "        mean_dice = torch.stack(dice_scores).mean()\n",
    "        return 1 - mean_dice\n",
    "\n",
    "\n",
    "class MultiClassCombinedLoss(nn.Module):\n",
    "    def __init__(self, num_classes: int, ce_weight=0.5, dice_weight=0.5):\n",
    "        super(MultiClassCombinedLoss, self).__init__()\n",
    "        self.ce_weight = ce_weight\n",
    "        self.dice_weight = dice_weight\n",
    "\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        self.dice_loss = MultiClassDiceLoss(num_classes)\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        ce = self.ce_loss(pred, target)\n",
    "        dice = self.dice_loss(pred, target)\n",
    "\n",
    "        combined_loss = self.ce_weight * ce + self.dice_weight * dice\n",
    "        return combined_loss"
   ],
   "id": "4f5c94a50b635ba2",
   "outputs": [],
   "execution_count": 146
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:35:05.875380Z",
     "start_time": "2025-12-04T09:35:05.862393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MultiClassSegmentationMetrics:\n",
    "    def __init__(self, num_classes: int, epsilon: float = 1e-7):\n",
    "        self.num_classes = num_classes\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def compute_dice_score(self, pred, target) -> float:\n",
    "        \"\"\"\n",
    "        Compute average Dice Score for multi-class segmentation.\n",
    "        Args:\n",
    "            pred: Predicted mask (B, C, H, W) - logits (after softmax)\n",
    "            target: Ground truth mask (B, H, W) - ground truth class indices {0, 1, ..., C-1}\n",
    "        \"\"\"\n",
    "        pred_classes = torch.argmax(pred, dim=1)  # [B, H, W]\n",
    "\n",
    "        # Convert pred and target to one-hot encoding\n",
    "        # [B, H, W, C] -> [B, C, H, W]\n",
    "        pred_oh = nn.functional.one_hot(pred_classes, self.num_classes)\n",
    "        pred_oh = pred_oh.permute(0, 3, 1, 2).float()\n",
    "\n",
    "        target_oh = nn.functional.one_hot(target, self.num_classes)\n",
    "        target_oh = target_oh.permute(0, 3, 1, 2).float()\n",
    "\n",
    "        # Compute Dice for each class\n",
    "        dice_scores = []\n",
    "        for cls in range(self.num_classes):\n",
    "            pred_cls = pred_oh[:, cls, :, :].contiguous().view(-1)\n",
    "            target_cls = target_oh[:, cls, :, :].contiguous().view(-1)\n",
    "\n",
    "            intersection = (pred_cls * target_cls).sum()\n",
    "            dice = (2. * intersection + self.epsilon) / (pred_cls.sum() + target_cls.sum() + self.epsilon)\n",
    "            dice_scores.append(dice)\n",
    "\n",
    "        # Average Dice score over all classes\n",
    "        mean_dice = torch.stack(dice_scores).mean()\n",
    "        return mean_dice.item()\n",
    "\n",
    "    def compute_iou(self, pred, target) -> float:\n",
    "        \"\"\"\n",
    "        Compute average IoU for multi-class segmentation.\n",
    "        Args:\n",
    "            pred: Predicted mask (B, C, H, W) - logits (after softmax)\n",
    "            target: Ground truth mask (B, H, W) - ground truth class indices {0, 1, ..., C-1}\n",
    "        \"\"\"\n",
    "        pred_classes = torch.argmax(pred, dim=1)  # [B, H, W]\n",
    "\n",
    "        # Convert pred and target to one-hot encoding\n",
    "        pred_oh = nn.functional.one_hot(pred_classes, self.num_classes)\n",
    "        pred_oh = pred_oh.permute(0, 3, 1, 2).float()\n",
    "\n",
    "        target_oh = nn.functional.one_hot(target, self.num_classes)\n",
    "        target_oh = target_oh.permute(0, 3, 1, 2).float()\n",
    "\n",
    "        # Compute IoU for each class\n",
    "        iou_scores = []\n",
    "        for cls in range(self.num_classes):\n",
    "            pred_cls = pred_oh[:, cls, :, :].contiguous().view(-1)\n",
    "            target_cls = target_oh[:, cls, :, :].contiguous().view(-1)\n",
    "\n",
    "            intersection = (pred_cls * target_cls).sum()\n",
    "            union = pred_cls.sum() + target_cls.sum() - intersection\n",
    "            iou = (intersection + self.epsilon) / (union + self.epsilon)\n",
    "            iou_scores.append(iou)\n",
    "\n",
    "        # Average IoU over all classes\n",
    "        mean_iou = torch.stack(iou_scores).mean()\n",
    "        return mean_iou.item()"
   ],
   "id": "68fe2a9997c74e8a",
   "outputs": [],
   "execution_count": 153
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### For Multi-class Segmentation",
   "id": "28aa4d74c5f3cfcc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T09:35:41.521393Z",
     "start_time": "2025-12-04T09:35:41.031762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "NUM_CLASSES = 3\n",
    "EPSILON = 1e-7\n",
    "THRESHOLD = 0.5\n",
    "BATCH_SIZE = 8\n",
    "HEIGHT, WIDTH = 128, 128\n",
    "CHANNELS = 3\n",
    "DEVICE = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Metrics\n",
    "metrics = MultiClassSegmentationMetrics(num_classes=NUM_CLASSES, epsilon=EPSILON)\n",
    "\n",
    "# Loss function\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# criterion = MultiClassDiceLoss(num_classes=NUM_CLASSES, epsilon=EPSILON)\n",
    "criterion = MultiClassCombinedLoss(num_classes=NUM_CLASSES)\n",
    "\n",
    "# num_classes = 3 for multi-class segmentation\n",
    "model = UNetBaseline(in_channels=CHANNELS, num_classes=NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "# 1. Init images and sample masks\n",
    "# Shape: [batch_size, channels, height, width] : [8, 3, 128, 128]\n",
    "images = torch.randn(BATCH_SIZE, CHANNELS, HEIGHT, WIDTH).to(DEVICE)\n",
    "# Shape: [batch_size, height, width] : [8, 128, 128]\n",
    "masks = torch.randint(0, NUM_CLASSES, (BATCH_SIZE, HEIGHT, WIDTH)).long().to(DEVICE)\n",
    "\n",
    "assert images.shape == (BATCH_SIZE, CHANNELS, HEIGHT, WIDTH)\n",
    "assert masks.shape == (BATCH_SIZE, HEIGHT, WIDTH)\n",
    "\n",
    "# 2. Forward pass\n",
    "# Shape: [batch_size, num_classes, height, width] : [8, 3, 128, 128]\n",
    "pred = model(images)\n",
    "assert pred.shape == (BATCH_SIZE, NUM_CLASSES, HEIGHT, WIDTH)\n",
    "\n",
    "# 3. Compute loss\n",
    "loss = criterion(pred, masks)  # Should be a float value\n",
    "\n",
    "# CrossEntropyLoss: 1.1529099941253662\n",
    "# MultiClassDiceLoss: 0.6677639484405518\n",
    "# MultiClassCombinedLoss: 0.910336971282959\n",
    "\n",
    "loss.item()\n",
    "\n",
    "# 4. Compute metrics\n",
    "iou = metrics.compute_iou(pred, masks)\n",
    "dice = metrics.compute_dice_score(pred, masks)\n",
    "\n",
    "print(f\"Loss: {loss.item()}\")\n",
    "print(f\"IoU: {iou}\")\n",
    "print(f\"Dice Score: {dice}\")"
   ],
   "id": "3367ea4a7ed7850b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.910336971282959\n",
      "IoU: 0.19103892147541046\n",
      "Dice Score: 0.31671738624572754\n"
     ]
    }
   ],
   "execution_count": 155
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
